{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOZxzgVs0XgQGC19RadW6ja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithindsouza/Image_Denoising_Autoencoder_Keras/blob/main/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3OFAQIiDpF_"
      },
      "source": [
        "###**Image Denoising Autoencoder**\n",
        "###With **Salt** And **Pepper** Noise\n",
        "Encoder : - a function f that compresses the input into a latent-space representation. f(x) = h\n",
        "\n",
        "Decoder : - a function g that reconstruct the input from the latent space representation. g(h) ~ x."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DweXBxm3DeI4"
      },
      "source": [
        "#importing dataset\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aicLeV-EVbk"
      },
      "source": [
        "#importing required libraries\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjtDzCy2EglZ",
        "outputId": "2587997c-f044-48f3-ccad-6d883a70f654"
      },
      "source": [
        "#Preprocessing of Dataset And Adding Salt and Pepper Noise to our dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "\n",
        "# to convert values from 0 to 255 into range 0 to 1.\n",
        "train_X = train_X.astype('float32') / 255.\n",
        "test_X = test_X.astype('float32') / 255.\n",
        "train_X = np.reshape(train_X, (len(train_X), 28, 28, 1)) \n",
        "test_X = np.reshape(test_X, (len(test_X), 28, 28, 1))  \n",
        "\n",
        "noise_factor = 0.5\n",
        "\n",
        "#np.random.normal => random means to obtain random samples\n",
        "#normal means normal or gaussian distribution, \n",
        "#i.e. random sample from gaussian distribution\n",
        "train_X_noisy = train_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=train_X.shape)  \n",
        "test_X_noisy = test_X + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=test_X.shape) \n",
        "\n",
        "# to make values in the range of 0 to 1, \n",
        "#if values < 0 then they will be equal to 0 and \n",
        "#if values > 1 then they will be equal to 1.\n",
        "train_X_noisy = np.clip(train_X_noisy, 0., 1.)   \n",
        "test_X_noisy = np.clip(test_X_noisy, 0., 1.)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf-3f5eRExL0"
      },
      "source": [
        "#Defining our Image denoising autoencoder using keras\n",
        "Input_img = Input(shape=(28, 28, 1))  \n",
        "\n",
        "#encoding architecture\n",
        "x1 = Conv2D(64, (3, 3), activation='relu', padding='same')(Input_img)\n",
        "x1 = MaxPool2D( (2, 2), padding='same')(x1)\n",
        "x2 = Conv2D(32, (3, 3), activation='relu', padding='same')(x1)\n",
        "x2 = MaxPool2D( (2, 2), padding='same')(x2)\n",
        "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(x2)\n",
        "encoded    = MaxPool2D( (2, 2), padding='same')(x3)\n",
        "\n",
        "# decoding architecture\n",
        "x3 = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x3 = UpSampling2D((2, 2))(x3)\n",
        "x2 = Conv2D(32, (3, 3), activation='relu', padding='same')(x3)\n",
        "x2 = UpSampling2D((2, 2))(x2)\n",
        "x1 = Conv2D(64, (3, 3), activation='relu')(x2)\n",
        "x1 = UpSampling2D((2, 2))(x1)\n",
        "decoded   = Conv2D(1, (3, 3), padding='same')(x1)\n",
        "\n",
        "autoencoder = Model(Input_img, decoded)\n",
        "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_II_XrFE2ah",
        "outputId": "eebbd1e7-211c-44f3-a68b-0f6bd401c911"
      },
      "source": [
        "#Structure of our Autoencoder\n",
        "autoencoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 28, 28, 64)        640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 16)          4624      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 4, 4, 16)          2320      \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 8, 8, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 (None, 28, 28, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 1)         577       \n",
            "=================================================================\n",
            "Total params: 49,761\n",
            "Trainable params: 49,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOe9IJ_9FJnx"
      },
      "source": [
        "#Performing Early Stopping and Then fitting training and testing data to our autoencoder\n",
        "from keras.callbacks import EarlyStopping\n",
        "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpyvnp-AFa3G",
        "outputId": "d3aa7827-64bb-422a-b6ba-72e487d66288"
      },
      "source": [
        "#Training our autoencoder and validating it on validation data\n",
        "a_e = autoencoder.fit(train_X_noisy, train_X,epochs=1000,batch_size=128,shuffle=True,validation_data=(test_X_noisy, test_X),callbacks=[early_stopper])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2118 - val_loss: 0.2115\n",
            "Epoch 2/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2117 - val_loss: 0.2114\n",
            "Epoch 3/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2116 - val_loss: 0.2113\n",
            "Epoch 4/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2115 - val_loss: 0.2112\n",
            "Epoch 5/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2115 - val_loss: 0.2111\n",
            "Epoch 6/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2114 - val_loss: 0.2111\n",
            "Epoch 7/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2113 - val_loss: 0.2110\n",
            "Epoch 8/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2112 - val_loss: 0.2109\n",
            "Epoch 9/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2112 - val_loss: 0.2108\n",
            "Epoch 10/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2111 - val_loss: 0.2108\n",
            "Epoch 11/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2110 - val_loss: 0.2107\n",
            "Epoch 12/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2109 - val_loss: 0.2107\n",
            "Epoch 13/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2109 - val_loss: 0.2106\n",
            "Epoch 14/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2108 - val_loss: 0.2105\n",
            "Epoch 15/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2107 - val_loss: 0.2104\n",
            "Epoch 16/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2107 - val_loss: 0.2103\n",
            "Epoch 17/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2106 - val_loss: 0.2103\n",
            "Epoch 18/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2105 - val_loss: 0.2102\n",
            "Epoch 19/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2105 - val_loss: 0.2102\n",
            "Epoch 20/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2104 - val_loss: 0.2101\n",
            "Epoch 21/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2103 - val_loss: 0.2100\n",
            "Epoch 22/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2103 - val_loss: 0.2099\n",
            "Epoch 23/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2102 - val_loss: 0.2099\n",
            "Epoch 24/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2102 - val_loss: 0.2098\n",
            "Epoch 25/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2101 - val_loss: 0.2098\n",
            "Epoch 26/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2100 - val_loss: 0.2097\n",
            "Epoch 27/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2099 - val_loss: 0.2096\n",
            "Epoch 28/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2099 - val_loss: 0.2096\n",
            "Epoch 29/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2099 - val_loss: 0.2095\n",
            "Epoch 30/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2098 - val_loss: 0.2094\n",
            "Epoch 31/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2097 - val_loss: 0.2093\n",
            "Epoch 32/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2096 - val_loss: 0.2093\n",
            "Epoch 33/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2095 - val_loss: 0.2092\n",
            "Epoch 34/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2095 - val_loss: 0.2092\n",
            "Epoch 35/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2094 - val_loss: 0.2090\n",
            "Epoch 36/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2093 - val_loss: 0.2090\n",
            "Epoch 37/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2093 - val_loss: 0.2090\n",
            "Epoch 38/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2092 - val_loss: 0.2090\n",
            "Epoch 39/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2092 - val_loss: 0.2088\n",
            "Epoch 40/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2091 - val_loss: 0.2089\n",
            "Epoch 41/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2091 - val_loss: 0.2087\n",
            "Epoch 42/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2090 - val_loss: 0.2087\n",
            "Epoch 43/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2089 - val_loss: 0.2086\n",
            "Epoch 44/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2089 - val_loss: 0.2085\n",
            "Epoch 45/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2088 - val_loss: 0.2084\n",
            "Epoch 46/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2087 - val_loss: 0.2085\n",
            "Epoch 47/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2087 - val_loss: 0.2084\n",
            "Epoch 48/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2086 - val_loss: 0.2083\n",
            "Epoch 49/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2085 - val_loss: 0.2082\n",
            "Epoch 50/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2085 - val_loss: 0.2081\n",
            "Epoch 51/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2085 - val_loss: 0.2081\n",
            "Epoch 52/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2084 - val_loss: 0.2080\n",
            "Epoch 53/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2083 - val_loss: 0.2079\n",
            "Epoch 54/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2082 - val_loss: 0.2079\n",
            "Epoch 55/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2082 - val_loss: 0.2079\n",
            "Epoch 56/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2081 - val_loss: 0.2078\n",
            "Epoch 57/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2080 - val_loss: 0.2077\n",
            "Epoch 58/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2080 - val_loss: 0.2076\n",
            "Epoch 59/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2079 - val_loss: 0.2075\n",
            "Epoch 60/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2078 - val_loss: 0.2075\n",
            "Epoch 61/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2078 - val_loss: 0.2074\n",
            "Epoch 62/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2077 - val_loss: 0.2073\n",
            "Epoch 63/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2077 - val_loss: 0.2073\n",
            "Epoch 64/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2076 - val_loss: 0.2073\n",
            "Epoch 65/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2076 - val_loss: 0.2072\n",
            "Epoch 66/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2075 - val_loss: 0.2072\n",
            "Epoch 67/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2075 - val_loss: 0.2071\n",
            "Epoch 68/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2074 - val_loss: 0.2070\n",
            "Epoch 69/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2073 - val_loss: 0.2070\n",
            "Epoch 70/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2073 - val_loss: 0.2070\n",
            "Epoch 71/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2072 - val_loss: 0.2069\n",
            "Epoch 72/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2071 - val_loss: 0.2068\n",
            "Epoch 73/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2071 - val_loss: 0.2067\n",
            "Epoch 74/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2070 - val_loss: 0.2066\n",
            "Epoch 75/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2069 - val_loss: 0.2066\n",
            "Epoch 76/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2069 - val_loss: 0.2065\n",
            "Epoch 77/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2068 - val_loss: 0.2065\n",
            "Epoch 78/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.2068 - val_loss: 0.2064\n",
            "Epoch 79/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2067 - val_loss: 0.2063\n",
            "Epoch 80/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2067 - val_loss: 0.2063\n",
            "Epoch 81/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2066 - val_loss: 0.2062\n",
            "Epoch 82/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2066 - val_loss: 0.2062\n",
            "Epoch 83/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2065 - val_loss: 0.2061\n",
            "Epoch 84/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2064 - val_loss: 0.2061\n",
            "Epoch 85/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2064 - val_loss: 0.2061\n",
            "Epoch 86/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2064 - val_loss: 0.2060\n",
            "Epoch 87/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2063 - val_loss: 0.2059\n",
            "Epoch 88/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2063 - val_loss: 0.2059\n",
            "Epoch 89/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2062 - val_loss: 0.2058\n",
            "Epoch 90/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2062 - val_loss: 0.2058\n",
            "Epoch 91/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2061 - val_loss: 0.2057\n",
            "Epoch 92/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2061 - val_loss: 0.2056\n",
            "Epoch 93/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2060 - val_loss: 0.2056\n",
            "Epoch 94/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2059 - val_loss: 0.2055\n",
            "Epoch 95/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2059 - val_loss: 0.2055\n",
            "Epoch 96/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2058 - val_loss: 0.2054\n",
            "Epoch 97/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2057 - val_loss: 0.2053\n",
            "Epoch 98/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2057 - val_loss: 0.2053\n",
            "Epoch 99/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2057 - val_loss: 0.2052\n",
            "Epoch 100/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2056 - val_loss: 0.2051\n",
            "Epoch 101/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2055 - val_loss: 0.2051\n",
            "Epoch 102/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2055 - val_loss: 0.2050\n",
            "Epoch 103/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2054 - val_loss: 0.2050\n",
            "Epoch 104/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2054 - val_loss: 0.2049\n",
            "Epoch 105/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2053 - val_loss: 0.2049\n",
            "Epoch 106/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2053 - val_loss: 0.2049\n",
            "Epoch 107/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2052 - val_loss: 0.2048\n",
            "Epoch 108/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2051 - val_loss: 0.2047\n",
            "Epoch 109/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2051 - val_loss: 0.2047\n",
            "Epoch 110/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2050 - val_loss: 0.2047\n",
            "Epoch 111/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2050 - val_loss: 0.2046\n",
            "Epoch 112/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2049 - val_loss: 0.2046\n",
            "Epoch 113/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2049 - val_loss: 0.2045\n",
            "Epoch 114/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2048 - val_loss: 0.2044\n",
            "Epoch 115/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2048 - val_loss: 0.2043\n",
            "Epoch 116/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2047 - val_loss: 0.2044\n",
            "Epoch 117/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2047 - val_loss: 0.2043\n",
            "Epoch 118/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2046 - val_loss: 0.2043\n",
            "Epoch 119/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2046 - val_loss: 0.2042\n",
            "Epoch 120/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2046 - val_loss: 0.2041\n",
            "Epoch 121/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2045 - val_loss: 0.2041\n",
            "Epoch 122/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2045 - val_loss: 0.2041\n",
            "Epoch 123/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2044 - val_loss: 0.2040\n",
            "Epoch 124/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2044 - val_loss: 0.2040\n",
            "Epoch 125/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2043 - val_loss: 0.2039\n",
            "Epoch 126/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2043 - val_loss: 0.2039\n",
            "Epoch 127/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2042 - val_loss: 0.2038\n",
            "Epoch 128/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2041 - val_loss: 0.2037\n",
            "Epoch 129/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2041 - val_loss: 0.2037\n",
            "Epoch 130/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2040 - val_loss: 0.2036\n",
            "Epoch 131/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2040 - val_loss: 0.2036\n",
            "Epoch 132/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2039 - val_loss: 0.2035\n",
            "Epoch 133/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2039 - val_loss: 0.2035\n",
            "Epoch 134/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2038 - val_loss: 0.2034\n",
            "Epoch 135/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2037 - val_loss: 0.2034\n",
            "Epoch 136/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2037 - val_loss: 0.2033\n",
            "Epoch 137/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2037 - val_loss: 0.2033\n",
            "Epoch 138/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2036 - val_loss: 0.2032\n",
            "Epoch 139/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2036 - val_loss: 0.2032\n",
            "Epoch 140/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2036 - val_loss: 0.2031\n",
            "Epoch 141/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2035 - val_loss: 0.2031\n",
            "Epoch 142/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2034 - val_loss: 0.2030\n",
            "Epoch 143/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2034 - val_loss: 0.2030\n",
            "Epoch 144/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2034 - val_loss: 0.2030\n",
            "Epoch 145/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2033 - val_loss: 0.2029\n",
            "Epoch 146/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2032 - val_loss: 0.2028\n",
            "Epoch 147/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2032 - val_loss: 0.2028\n",
            "Epoch 148/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2032 - val_loss: 0.2027\n",
            "Epoch 149/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2031 - val_loss: 0.2026\n",
            "Epoch 150/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2030 - val_loss: 0.2026\n",
            "Epoch 151/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2030 - val_loss: 0.2026\n",
            "Epoch 152/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2029 - val_loss: 0.2025\n",
            "Epoch 153/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2029 - val_loss: 0.2024\n",
            "Epoch 154/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2028 - val_loss: 0.2024\n",
            "Epoch 155/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2028 - val_loss: 0.2024\n",
            "Epoch 156/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2028 - val_loss: 0.2023\n",
            "Epoch 157/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2027 - val_loss: 0.2023\n",
            "Epoch 158/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2027 - val_loss: 0.2022\n",
            "Epoch 159/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2026 - val_loss: 0.2022\n",
            "Epoch 160/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2025 - val_loss: 0.2021\n",
            "Epoch 161/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2025 - val_loss: 0.2021\n",
            "Epoch 162/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2025 - val_loss: 0.2020\n",
            "Epoch 163/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2024 - val_loss: 0.2019\n",
            "Epoch 164/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2024 - val_loss: 0.2019\n",
            "Epoch 165/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2023 - val_loss: 0.2019\n",
            "Epoch 166/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2023 - val_loss: 0.2018\n",
            "Epoch 167/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2023 - val_loss: 0.2018\n",
            "Epoch 168/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2022 - val_loss: 0.2017\n",
            "Epoch 169/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2022 - val_loss: 0.2017\n",
            "Epoch 170/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2021 - val_loss: 0.2017\n",
            "Epoch 171/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2021 - val_loss: 0.2016\n",
            "Epoch 172/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2020 - val_loss: 0.2015\n",
            "Epoch 173/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2020 - val_loss: 0.2015\n",
            "Epoch 174/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2019 - val_loss: 0.2014\n",
            "Epoch 175/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2019 - val_loss: 0.2013\n",
            "Epoch 176/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2018 - val_loss: 0.2013\n",
            "Epoch 177/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2018 - val_loss: 0.2013\n",
            "Epoch 178/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2017 - val_loss: 0.2013\n",
            "Epoch 179/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2017 - val_loss: 0.2012\n",
            "Epoch 180/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2017 - val_loss: 0.2012\n",
            "Epoch 181/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2017 - val_loss: 0.2011\n",
            "Epoch 182/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2016 - val_loss: 0.2011\n",
            "Epoch 183/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2015 - val_loss: 0.2010\n",
            "Epoch 184/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2015 - val_loss: 0.2010\n",
            "Epoch 185/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2014 - val_loss: 0.2009\n",
            "Epoch 186/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2014 - val_loss: 0.2009\n",
            "Epoch 187/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2013 - val_loss: 0.2009\n",
            "Epoch 188/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2013 - val_loss: 0.2008\n",
            "Epoch 189/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2013 - val_loss: 0.2007\n",
            "Epoch 190/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2012 - val_loss: 0.2007\n",
            "Epoch 191/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2012 - val_loss: 0.2007\n",
            "Epoch 192/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2011 - val_loss: 0.2006\n",
            "Epoch 193/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2011 - val_loss: 0.2006\n",
            "Epoch 194/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2010 - val_loss: 0.2005\n",
            "Epoch 195/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2010 - val_loss: 0.2005\n",
            "Epoch 196/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2009 - val_loss: 0.2004\n",
            "Epoch 197/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2009 - val_loss: 0.2003\n",
            "Epoch 198/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2008 - val_loss: 0.2004\n",
            "Epoch 199/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2009 - val_loss: 0.2003\n",
            "Epoch 200/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2008 - val_loss: 0.2003\n",
            "Epoch 201/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2007 - val_loss: 0.2002\n",
            "Epoch 202/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2007 - val_loss: 0.2002\n",
            "Epoch 203/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2006 - val_loss: 0.2001\n",
            "Epoch 204/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2006 - val_loss: 0.2001\n",
            "Epoch 205/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2006 - val_loss: 0.2000\n",
            "Epoch 206/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2005 - val_loss: 0.2001\n",
            "Epoch 207/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2005 - val_loss: 0.2000\n",
            "Epoch 208/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2005 - val_loss: 0.2000\n",
            "Epoch 209/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2004 - val_loss: 0.1999\n",
            "Epoch 210/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2003 - val_loss: 0.1998\n",
            "Epoch 211/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2003 - val_loss: 0.1998\n",
            "Epoch 212/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2003 - val_loss: 0.1997\n",
            "Epoch 213/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2002 - val_loss: 0.1997\n",
            "Epoch 214/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2002 - val_loss: 0.1996\n",
            "Epoch 215/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.2001 - val_loss: 0.1996\n",
            "Epoch 216/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2001 - val_loss: 0.1995\n",
            "Epoch 217/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.2000 - val_loss: 0.1995\n",
            "Epoch 218/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1999 - val_loss: 0.1994\n",
            "Epoch 219/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1999 - val_loss: 0.1994\n",
            "Epoch 220/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1999 - val_loss: 0.1994\n",
            "Epoch 221/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1998 - val_loss: 0.1993\n",
            "Epoch 222/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1998 - val_loss: 0.1993\n",
            "Epoch 223/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1998 - val_loss: 0.1992\n",
            "Epoch 224/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1997 - val_loss: 0.1992\n",
            "Epoch 225/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1997 - val_loss: 0.1992\n",
            "Epoch 226/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1996 - val_loss: 0.1992\n",
            "Epoch 227/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1996 - val_loss: 0.1991\n",
            "Epoch 228/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1996 - val_loss: 0.1991\n",
            "Epoch 229/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1995 - val_loss: 0.1990\n",
            "Epoch 230/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1995 - val_loss: 0.1989\n",
            "Epoch 231/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1995 - val_loss: 0.1990\n",
            "Epoch 232/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1994 - val_loss: 0.1988\n",
            "Epoch 233/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1994 - val_loss: 0.1989\n",
            "Epoch 234/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1993 - val_loss: 0.1988\n",
            "Epoch 235/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1993 - val_loss: 0.1987\n",
            "Epoch 236/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1993 - val_loss: 0.1987\n",
            "Epoch 237/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1992 - val_loss: 0.1987\n",
            "Epoch 238/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1992 - val_loss: 0.1986\n",
            "Epoch 239/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1991 - val_loss: 0.1986\n",
            "Epoch 240/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1991 - val_loss: 0.1985\n",
            "Epoch 241/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1991 - val_loss: 0.1985\n",
            "Epoch 242/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1990 - val_loss: 0.1984\n",
            "Epoch 243/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1990 - val_loss: 0.1985\n",
            "Epoch 244/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1990 - val_loss: 0.1984\n",
            "Epoch 245/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1989 - val_loss: 0.1983\n",
            "Epoch 246/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1989 - val_loss: 0.1983\n",
            "Epoch 247/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1988 - val_loss: 0.1982\n",
            "Epoch 248/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1988 - val_loss: 0.1982\n",
            "Epoch 249/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1987 - val_loss: 0.1982\n",
            "Epoch 250/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1987 - val_loss: 0.1982\n",
            "Epoch 251/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1987 - val_loss: 0.1981\n",
            "Epoch 252/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1986 - val_loss: 0.1980\n",
            "Epoch 253/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1985 - val_loss: 0.1980\n",
            "Epoch 254/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1985 - val_loss: 0.1979\n",
            "Epoch 255/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1984 - val_loss: 0.1978\n",
            "Epoch 256/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1984 - val_loss: 0.1978\n",
            "Epoch 257/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1983 - val_loss: 0.1977\n",
            "Epoch 258/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1983 - val_loss: 0.1977\n",
            "Epoch 259/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1983 - val_loss: 0.1977\n",
            "Epoch 260/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1982 - val_loss: 0.1977\n",
            "Epoch 261/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1982 - val_loss: 0.1977\n",
            "Epoch 262/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1982 - val_loss: 0.1976\n",
            "Epoch 263/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1981 - val_loss: 0.1976\n",
            "Epoch 264/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1981 - val_loss: 0.1975\n",
            "Epoch 265/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1980 - val_loss: 0.1975\n",
            "Epoch 266/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1980 - val_loss: 0.1974\n",
            "Epoch 267/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1979 - val_loss: 0.1974\n",
            "Epoch 268/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1980 - val_loss: 0.1973\n",
            "Epoch 269/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1979 - val_loss: 0.1973\n",
            "Epoch 270/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1978 - val_loss: 0.1972\n",
            "Epoch 271/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1978 - val_loss: 0.1972\n",
            "Epoch 272/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1978 - val_loss: 0.1972\n",
            "Epoch 273/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1977 - val_loss: 0.1972\n",
            "Epoch 274/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1977 - val_loss: 0.1971\n",
            "Epoch 275/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1977 - val_loss: 0.1971\n",
            "Epoch 276/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1977 - val_loss: 0.1972\n",
            "Epoch 277/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1977 - val_loss: 0.1971\n",
            "Epoch 278/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1976 - val_loss: 0.1971\n",
            "Epoch 279/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1976 - val_loss: 0.1970\n",
            "Epoch 280/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1975 - val_loss: 0.1969\n",
            "Epoch 281/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1975 - val_loss: 0.1968\n",
            "Epoch 282/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1974 - val_loss: 0.1968\n",
            "Epoch 283/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1974 - val_loss: 0.1968\n",
            "Epoch 284/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1974 - val_loss: 0.1968\n",
            "Epoch 285/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1974 - val_loss: 0.1967\n",
            "Epoch 286/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1973 - val_loss: 0.1967\n",
            "Epoch 287/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1973 - val_loss: 0.1967\n",
            "Epoch 288/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1973 - val_loss: 0.1966\n",
            "Epoch 289/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1972 - val_loss: 0.1966\n",
            "Epoch 290/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1972 - val_loss: 0.1966\n",
            "Epoch 291/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1972 - val_loss: 0.1965\n",
            "Epoch 292/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1971 - val_loss: 0.1965\n",
            "Epoch 293/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1971 - val_loss: 0.1965\n",
            "Epoch 294/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1971 - val_loss: 0.1964\n",
            "Epoch 295/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1970 - val_loss: 0.1963\n",
            "Epoch 296/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1969 - val_loss: 0.1964\n",
            "Epoch 297/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1969 - val_loss: 0.1963\n",
            "Epoch 298/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1969 - val_loss: 0.1963\n",
            "Epoch 299/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1968 - val_loss: 0.1962\n",
            "Epoch 300/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1968 - val_loss: 0.1962\n",
            "Epoch 301/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1967 - val_loss: 0.1961\n",
            "Epoch 302/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1967 - val_loss: 0.1962\n",
            "Epoch 303/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1967 - val_loss: 0.1961\n",
            "Epoch 304/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1967 - val_loss: 0.1960\n",
            "Epoch 305/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1966 - val_loss: 0.1960\n",
            "Epoch 306/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1966 - val_loss: 0.1959\n",
            "Epoch 307/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1965 - val_loss: 0.1959\n",
            "Epoch 308/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1965 - val_loss: 0.1959\n",
            "Epoch 309/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1964 - val_loss: 0.1958\n",
            "Epoch 310/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1964 - val_loss: 0.1958\n",
            "Epoch 311/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1964 - val_loss: 0.1958\n",
            "Epoch 312/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1964 - val_loss: 0.1957\n",
            "Epoch 313/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1963 - val_loss: 0.1957\n",
            "Epoch 314/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1962 - val_loss: 0.1956\n",
            "Epoch 315/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1962 - val_loss: 0.1956\n",
            "Epoch 316/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1962 - val_loss: 0.1955\n",
            "Epoch 317/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1962 - val_loss: 0.1955\n",
            "Epoch 318/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1961 - val_loss: 0.1955\n",
            "Epoch 319/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1961 - val_loss: 0.1954\n",
            "Epoch 320/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1960 - val_loss: 0.1954\n",
            "Epoch 321/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1960 - val_loss: 0.1953\n",
            "Epoch 322/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1960 - val_loss: 0.1953\n",
            "Epoch 323/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1959 - val_loss: 0.1953\n",
            "Epoch 324/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1959 - val_loss: 0.1952\n",
            "Epoch 325/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1958 - val_loss: 0.1952\n",
            "Epoch 326/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1958 - val_loss: 0.1952\n",
            "Epoch 327/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1958 - val_loss: 0.1952\n",
            "Epoch 328/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1958 - val_loss: 0.1951\n",
            "Epoch 329/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1957 - val_loss: 0.1951\n",
            "Epoch 330/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1957 - val_loss: 0.1951\n",
            "Epoch 331/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1957 - val_loss: 0.1951\n",
            "Epoch 332/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1957 - val_loss: 0.1950\n",
            "Epoch 333/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1957 - val_loss: 0.1950\n",
            "Epoch 334/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1956 - val_loss: 0.1950\n",
            "Epoch 335/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1956 - val_loss: 0.1949\n",
            "Epoch 336/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1955 - val_loss: 0.1949\n",
            "Epoch 337/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1955 - val_loss: 0.1949\n",
            "Epoch 338/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1955 - val_loss: 0.1948\n",
            "Epoch 339/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1953 - val_loss: 0.1947\n",
            "Epoch 340/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1953 - val_loss: 0.1947\n",
            "Epoch 341/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1953 - val_loss: 0.1947\n",
            "Epoch 342/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1953 - val_loss: 0.1947\n",
            "Epoch 343/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1953 - val_loss: 0.1947\n",
            "Epoch 344/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1952 - val_loss: 0.1946\n",
            "Epoch 345/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1952 - val_loss: 0.1945\n",
            "Epoch 346/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1952 - val_loss: 0.1946\n",
            "Epoch 347/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1952 - val_loss: 0.1945\n",
            "Epoch 348/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1951 - val_loss: 0.1945\n",
            "Epoch 349/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1951 - val_loss: 0.1944\n",
            "Epoch 350/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1950 - val_loss: 0.1945\n",
            "Epoch 351/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1950 - val_loss: 0.1944\n",
            "Epoch 352/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1950 - val_loss: 0.1943\n",
            "Epoch 353/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1949 - val_loss: 0.1943\n",
            "Epoch 354/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1949 - val_loss: 0.1943\n",
            "Epoch 355/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1949 - val_loss: 0.1942\n",
            "Epoch 356/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1948 - val_loss: 0.1942\n",
            "Epoch 357/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1948 - val_loss: 0.1941\n",
            "Epoch 358/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1947 - val_loss: 0.1941\n",
            "Epoch 359/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1947 - val_loss: 0.1941\n",
            "Epoch 360/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1947 - val_loss: 0.1940\n",
            "Epoch 361/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1946 - val_loss: 0.1940\n",
            "Epoch 362/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1946 - val_loss: 0.1940\n",
            "Epoch 363/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1946 - val_loss: 0.1940\n",
            "Epoch 364/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1946 - val_loss: 0.1939\n",
            "Epoch 365/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1945 - val_loss: 0.1939\n",
            "Epoch 366/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1945 - val_loss: 0.1938\n",
            "Epoch 367/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1944 - val_loss: 0.1938\n",
            "Epoch 368/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1944 - val_loss: 0.1938\n",
            "Epoch 369/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1944 - val_loss: 0.1938\n",
            "Epoch 370/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1944 - val_loss: 0.1937\n",
            "Epoch 371/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1943 - val_loss: 0.1937\n",
            "Epoch 372/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1943 - val_loss: 0.1936\n",
            "Epoch 373/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1942 - val_loss: 0.1936\n",
            "Epoch 374/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1942 - val_loss: 0.1936\n",
            "Epoch 375/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1942 - val_loss: 0.1935\n",
            "Epoch 376/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1941 - val_loss: 0.1935\n",
            "Epoch 377/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1941 - val_loss: 0.1935\n",
            "Epoch 378/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1941 - val_loss: 0.1935\n",
            "Epoch 379/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1940 - val_loss: 0.1934\n",
            "Epoch 380/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1941 - val_loss: 0.1934\n",
            "Epoch 381/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1940 - val_loss: 0.1933\n",
            "Epoch 382/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1940 - val_loss: 0.1933\n",
            "Epoch 383/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1939 - val_loss: 0.1933\n",
            "Epoch 384/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1939 - val_loss: 0.1933\n",
            "Epoch 385/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1939 - val_loss: 0.1932\n",
            "Epoch 386/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1938 - val_loss: 0.1932\n",
            "Epoch 387/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1938 - val_loss: 0.1931\n",
            "Epoch 388/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1938 - val_loss: 0.1931\n",
            "Epoch 389/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1938 - val_loss: 0.1931\n",
            "Epoch 390/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1937 - val_loss: 0.1931\n",
            "Epoch 391/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1937 - val_loss: 0.1930\n",
            "Epoch 392/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1937 - val_loss: 0.1930\n",
            "Epoch 393/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1936 - val_loss: 0.1930\n",
            "Epoch 394/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1936 - val_loss: 0.1930\n",
            "Epoch 395/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1936 - val_loss: 0.1929\n",
            "Epoch 396/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1935 - val_loss: 0.1930\n",
            "Epoch 397/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1935 - val_loss: 0.1928\n",
            "Epoch 398/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1935 - val_loss: 0.1929\n",
            "Epoch 399/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1934 - val_loss: 0.1928\n",
            "Epoch 400/1000\n",
            "469/469 [==============================] - 5s 11ms/step - loss: 0.1934 - val_loss: 0.1927\n",
            "Epoch 401/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1934 - val_loss: 0.1927\n",
            "Epoch 402/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1934 - val_loss: 0.1927\n",
            "Epoch 403/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1933 - val_loss: 0.1927\n",
            "Epoch 404/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1933 - val_loss: 0.1928\n",
            "Epoch 405/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1933 - val_loss: 0.1926\n",
            "Epoch 406/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1933 - val_loss: 0.1926\n",
            "Epoch 407/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1932 - val_loss: 0.1925\n",
            "Epoch 408/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1932 - val_loss: 0.1926\n",
            "Epoch 409/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1932 - val_loss: 0.1926\n",
            "Epoch 410/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1932 - val_loss: 0.1925\n",
            "Epoch 411/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1931 - val_loss: 0.1925\n",
            "Epoch 412/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1931 - val_loss: 0.1924\n",
            "Epoch 413/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1931 - val_loss: 0.1924\n",
            "Epoch 414/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1930 - val_loss: 0.1924\n",
            "Epoch 415/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1930 - val_loss: 0.1923\n",
            "Epoch 416/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1930 - val_loss: 0.1923\n",
            "Epoch 417/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1929 - val_loss: 0.1923\n",
            "Epoch 418/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1929 - val_loss: 0.1922\n",
            "Epoch 419/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1929 - val_loss: 0.1922\n",
            "Epoch 420/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1928 - val_loss: 0.1922\n",
            "Epoch 421/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1928 - val_loss: 0.1921\n",
            "Epoch 422/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1928 - val_loss: 0.1921\n",
            "Epoch 423/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1927 - val_loss: 0.1921\n",
            "Epoch 424/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1927 - val_loss: 0.1920\n",
            "Epoch 425/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1927 - val_loss: 0.1920\n",
            "Epoch 426/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1926 - val_loss: 0.1919\n",
            "Epoch 427/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1926 - val_loss: 0.1920\n",
            "Epoch 428/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1926 - val_loss: 0.1919\n",
            "Epoch 429/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1925 - val_loss: 0.1918\n",
            "Epoch 430/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1925 - val_loss: 0.1918\n",
            "Epoch 431/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1925 - val_loss: 0.1919\n",
            "Epoch 432/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1925 - val_loss: 0.1918\n",
            "Epoch 433/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1924 - val_loss: 0.1917\n",
            "Epoch 434/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1924 - val_loss: 0.1917\n",
            "Epoch 435/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1924 - val_loss: 0.1917\n",
            "Epoch 436/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1923 - val_loss: 0.1916\n",
            "Epoch 437/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1923 - val_loss: 0.1916\n",
            "Epoch 438/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1923 - val_loss: 0.1916\n",
            "Epoch 439/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1923 - val_loss: 0.1916\n",
            "Epoch 440/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1922 - val_loss: 0.1915\n",
            "Epoch 441/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1923 - val_loss: 0.1916\n",
            "Epoch 442/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1922 - val_loss: 0.1915\n",
            "Epoch 443/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1922 - val_loss: 0.1914\n",
            "Epoch 444/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1921 - val_loss: 0.1914\n",
            "Epoch 445/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1921 - val_loss: 0.1914\n",
            "Epoch 446/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1921 - val_loss: 0.1914\n",
            "Epoch 447/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1921 - val_loss: 0.1914\n",
            "Epoch 448/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1920 - val_loss: 0.1913\n",
            "Epoch 449/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1920 - val_loss: 0.1913\n",
            "Epoch 450/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1920 - val_loss: 0.1913\n",
            "Epoch 451/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1919 - val_loss: 0.1913\n",
            "Epoch 452/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1919 - val_loss: 0.1912\n",
            "Epoch 453/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1919 - val_loss: 0.1912\n",
            "Epoch 454/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1918 - val_loss: 0.1911\n",
            "Epoch 455/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1918 - val_loss: 0.1912\n",
            "Epoch 456/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1918 - val_loss: 0.1911\n",
            "Epoch 457/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1918 - val_loss: 0.1911\n",
            "Epoch 458/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1918 - val_loss: 0.1911\n",
            "Epoch 459/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1917 - val_loss: 0.1911\n",
            "Epoch 460/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1916 - val_loss: 0.1909\n",
            "Epoch 461/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1916 - val_loss: 0.1910\n",
            "Epoch 462/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1916 - val_loss: 0.1909\n",
            "Epoch 463/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1916 - val_loss: 0.1909\n",
            "Epoch 464/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1915 - val_loss: 0.1908\n",
            "Epoch 465/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1915 - val_loss: 0.1909\n",
            "Epoch 466/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1915 - val_loss: 0.1909\n",
            "Epoch 467/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1915 - val_loss: 0.1908\n",
            "Epoch 468/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1915 - val_loss: 0.1908\n",
            "Epoch 469/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1914 - val_loss: 0.1907\n",
            "Epoch 470/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1914 - val_loss: 0.1906\n",
            "Epoch 471/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1913 - val_loss: 0.1906\n",
            "Epoch 472/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1913 - val_loss: 0.1906\n",
            "Epoch 473/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1913 - val_loss: 0.1906\n",
            "Epoch 474/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1912 - val_loss: 0.1905\n",
            "Epoch 475/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1912 - val_loss: 0.1905\n",
            "Epoch 476/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1913 - val_loss: 0.1905\n",
            "Epoch 477/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1912 - val_loss: 0.1906\n",
            "Epoch 478/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1912 - val_loss: 0.1905\n",
            "Epoch 479/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1911 - val_loss: 0.1904\n",
            "Epoch 480/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1911 - val_loss: 0.1905\n",
            "Epoch 481/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1912 - val_loss: 0.1904\n",
            "Epoch 482/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1911 - val_loss: 0.1904\n",
            "Epoch 483/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1910 - val_loss: 0.1903\n",
            "Epoch 484/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1910 - val_loss: 0.1903\n",
            "Epoch 485/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1910 - val_loss: 0.1903\n",
            "Epoch 486/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1909 - val_loss: 0.1902\n",
            "Epoch 487/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1909 - val_loss: 0.1902\n",
            "Epoch 488/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1908 - val_loss: 0.1901\n",
            "Epoch 489/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1908 - val_loss: 0.1901\n",
            "Epoch 490/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1908 - val_loss: 0.1900\n",
            "Epoch 491/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1908 - val_loss: 0.1902\n",
            "Epoch 492/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1907 - val_loss: 0.1900\n",
            "Epoch 493/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1907 - val_loss: 0.1900\n",
            "Epoch 494/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1907 - val_loss: 0.1900\n",
            "Epoch 495/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1907 - val_loss: 0.1900\n",
            "Epoch 496/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1906 - val_loss: 0.1899\n",
            "Epoch 497/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1906 - val_loss: 0.1899\n",
            "Epoch 498/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1906 - val_loss: 0.1899\n",
            "Epoch 499/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1906 - val_loss: 0.1898\n",
            "Epoch 500/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1905 - val_loss: 0.1898\n",
            "Epoch 501/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1905 - val_loss: 0.1898\n",
            "Epoch 502/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1905 - val_loss: 0.1897\n",
            "Epoch 503/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1905 - val_loss: 0.1898\n",
            "Epoch 504/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1905 - val_loss: 0.1897\n",
            "Epoch 505/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1904 - val_loss: 0.1897\n",
            "Epoch 506/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1903 - val_loss: 0.1897\n",
            "Epoch 507/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1903 - val_loss: 0.1896\n",
            "Epoch 508/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1903 - val_loss: 0.1897\n",
            "Epoch 509/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1903 - val_loss: 0.1895\n",
            "Epoch 510/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1902 - val_loss: 0.1896\n",
            "Epoch 511/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1902 - val_loss: 0.1895\n",
            "Epoch 512/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1902 - val_loss: 0.1895\n",
            "Epoch 513/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1902 - val_loss: 0.1894\n",
            "Epoch 514/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1901 - val_loss: 0.1894\n",
            "Epoch 515/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1901 - val_loss: 0.1894\n",
            "Epoch 516/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1900 - val_loss: 0.1894\n",
            "Epoch 517/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1900 - val_loss: 0.1893\n",
            "Epoch 518/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1900 - val_loss: 0.1892\n",
            "Epoch 519/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1900 - val_loss: 0.1892\n",
            "Epoch 520/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1900 - val_loss: 0.1894\n",
            "Epoch 521/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1900 - val_loss: 0.1892\n",
            "Epoch 522/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1899 - val_loss: 0.1893\n",
            "Epoch 523/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1899 - val_loss: 0.1892\n",
            "Epoch 524/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1899 - val_loss: 0.1892\n",
            "Epoch 525/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1898 - val_loss: 0.1891\n",
            "Epoch 526/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1898 - val_loss: 0.1891\n",
            "Epoch 527/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1898 - val_loss: 0.1891\n",
            "Epoch 528/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1897 - val_loss: 0.1891\n",
            "Epoch 529/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1897 - val_loss: 0.1890\n",
            "Epoch 530/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1897 - val_loss: 0.1889\n",
            "Epoch 531/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1896 - val_loss: 0.1890\n",
            "Epoch 532/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1896 - val_loss: 0.1889\n",
            "Epoch 533/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1896 - val_loss: 0.1888\n",
            "Epoch 534/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1896 - val_loss: 0.1889\n",
            "Epoch 535/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1895 - val_loss: 0.1888\n",
            "Epoch 536/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1895 - val_loss: 0.1888\n",
            "Epoch 537/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1895 - val_loss: 0.1888\n",
            "Epoch 538/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1895 - val_loss: 0.1887\n",
            "Epoch 539/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1894 - val_loss: 0.1887\n",
            "Epoch 540/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1894 - val_loss: 0.1887\n",
            "Epoch 541/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1894 - val_loss: 0.1886\n",
            "Epoch 542/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1894 - val_loss: 0.1887\n",
            "Epoch 543/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1894 - val_loss: 0.1886\n",
            "Epoch 544/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1893 - val_loss: 0.1886\n",
            "Epoch 545/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1893 - val_loss: 0.1886\n",
            "Epoch 546/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1893 - val_loss: 0.1885\n",
            "Epoch 547/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1893 - val_loss: 0.1885\n",
            "Epoch 548/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1892 - val_loss: 0.1885\n",
            "Epoch 549/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1891 - val_loss: 0.1884\n",
            "Epoch 550/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1891 - val_loss: 0.1884\n",
            "Epoch 551/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1891 - val_loss: 0.1884\n",
            "Epoch 552/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1891 - val_loss: 0.1883\n",
            "Epoch 553/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1891 - val_loss: 0.1883\n",
            "Epoch 554/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1891 - val_loss: 0.1883\n",
            "Epoch 555/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1890 - val_loss: 0.1882\n",
            "Epoch 556/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1890 - val_loss: 0.1883\n",
            "Epoch 557/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1890 - val_loss: 0.1882\n",
            "Epoch 558/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1889 - val_loss: 0.1883\n",
            "Epoch 559/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1889 - val_loss: 0.1882\n",
            "Epoch 560/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1889 - val_loss: 0.1882\n",
            "Epoch 561/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1889 - val_loss: 0.1882\n",
            "Epoch 562/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1889 - val_loss: 0.1881\n",
            "Epoch 563/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1888 - val_loss: 0.1881\n",
            "Epoch 564/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1888 - val_loss: 0.1880\n",
            "Epoch 565/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1888 - val_loss: 0.1880\n",
            "Epoch 566/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1887 - val_loss: 0.1880\n",
            "Epoch 567/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1887 - val_loss: 0.1881\n",
            "Epoch 568/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1887 - val_loss: 0.1879\n",
            "Epoch 569/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1887 - val_loss: 0.1879\n",
            "Epoch 570/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1887 - val_loss: 0.1880\n",
            "Epoch 571/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1887 - val_loss: 0.1879\n",
            "Epoch 572/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1886 - val_loss: 0.1879\n",
            "Epoch 573/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1886 - val_loss: 0.1878\n",
            "Epoch 574/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1886 - val_loss: 0.1879\n",
            "Epoch 575/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1886 - val_loss: 0.1878\n",
            "Epoch 576/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1885 - val_loss: 0.1878\n",
            "Epoch 577/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1885 - val_loss: 0.1877\n",
            "Epoch 578/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1884 - val_loss: 0.1877\n",
            "Epoch 579/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1885 - val_loss: 0.1877\n",
            "Epoch 580/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1884 - val_loss: 0.1877\n",
            "Epoch 581/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1884 - val_loss: 0.1877\n",
            "Epoch 582/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1884 - val_loss: 0.1877\n",
            "Epoch 583/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1884 - val_loss: 0.1877\n",
            "Epoch 584/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1884 - val_loss: 0.1876\n",
            "Epoch 585/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1884 - val_loss: 0.1877\n",
            "Epoch 586/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1883 - val_loss: 0.1876\n",
            "Epoch 587/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1883 - val_loss: 0.1875\n",
            "Epoch 588/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1883 - val_loss: 0.1875\n",
            "Epoch 589/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1882 - val_loss: 0.1875\n",
            "Epoch 590/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1882 - val_loss: 0.1876\n",
            "Epoch 591/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1882 - val_loss: 0.1875\n",
            "Epoch 592/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1882 - val_loss: 0.1875\n",
            "Epoch 593/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1882 - val_loss: 0.1874\n",
            "Epoch 594/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1882 - val_loss: 0.1874\n",
            "Epoch 595/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1881 - val_loss: 0.1873\n",
            "Epoch 596/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1881 - val_loss: 0.1873\n",
            "Epoch 597/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1881 - val_loss: 0.1873\n",
            "Epoch 598/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1881 - val_loss: 0.1873\n",
            "Epoch 599/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1881 - val_loss: 0.1873\n",
            "Epoch 600/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1880 - val_loss: 0.1872\n",
            "Epoch 601/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1880 - val_loss: 0.1872\n",
            "Epoch 602/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1879 - val_loss: 0.1871\n",
            "Epoch 603/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1879 - val_loss: 0.1871\n",
            "Epoch 604/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1879 - val_loss: 0.1871\n",
            "Epoch 605/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1879 - val_loss: 0.1871\n",
            "Epoch 606/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1879 - val_loss: 0.1871\n",
            "Epoch 607/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1878 - val_loss: 0.1870\n",
            "Epoch 608/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1878 - val_loss: 0.1871\n",
            "Epoch 609/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1878 - val_loss: 0.1870\n",
            "Epoch 610/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1878 - val_loss: 0.1870\n",
            "Epoch 611/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1877 - val_loss: 0.1869\n",
            "Epoch 612/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1877 - val_loss: 0.1870\n",
            "Epoch 613/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1877 - val_loss: 0.1869\n",
            "Epoch 614/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1876 - val_loss: 0.1869\n",
            "Epoch 615/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1876 - val_loss: 0.1868\n",
            "Epoch 616/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1876 - val_loss: 0.1869\n",
            "Epoch 617/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1876 - val_loss: 0.1868\n",
            "Epoch 618/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1875 - val_loss: 0.1868\n",
            "Epoch 619/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1875 - val_loss: 0.1867\n",
            "Epoch 620/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1875 - val_loss: 0.1867\n",
            "Epoch 621/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1875 - val_loss: 0.1868\n",
            "Epoch 622/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1875 - val_loss: 0.1868\n",
            "Epoch 623/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1874 - val_loss: 0.1866\n",
            "Epoch 624/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1874 - val_loss: 0.1867\n",
            "Epoch 625/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1874 - val_loss: 0.1867\n",
            "Epoch 626/1000\n",
            "469/469 [==============================] - 5s 12ms/step - loss: 0.1874 - val_loss: 0.1866\n",
            "Epoch 627/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1873 - val_loss: 0.1865\n",
            "Epoch 628/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1873 - val_loss: 0.1866\n",
            "Epoch 629/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1873 - val_loss: 0.1866\n",
            "Epoch 630/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1873 - val_loss: 0.1865\n",
            "Epoch 631/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1872 - val_loss: 0.1865\n",
            "Epoch 632/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1872 - val_loss: 0.1865\n",
            "Epoch 633/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1872 - val_loss: 0.1864\n",
            "Epoch 634/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1872 - val_loss: 0.1865\n",
            "Epoch 635/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1872 - val_loss: 0.1865\n",
            "Epoch 636/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1872 - val_loss: 0.1864\n",
            "Epoch 637/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1871 - val_loss: 0.1863\n",
            "Epoch 638/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1871 - val_loss: 0.1863\n",
            "Epoch 639/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1871 - val_loss: 0.1863\n",
            "Epoch 640/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1871 - val_loss: 0.1863\n",
            "Epoch 641/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1871 - val_loss: 0.1863\n",
            "Epoch 642/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1871 - val_loss: 0.1863\n",
            "Epoch 643/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1870 - val_loss: 0.1862\n",
            "Epoch 644/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1870 - val_loss: 0.1862\n",
            "Epoch 645/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1870 - val_loss: 0.1863\n",
            "Epoch 646/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1870 - val_loss: 0.1861\n",
            "Epoch 647/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1869 - val_loss: 0.1862\n",
            "Epoch 648/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1869 - val_loss: 0.1862\n",
            "Epoch 649/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1869 - val_loss: 0.1861\n",
            "Epoch 650/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1868 - val_loss: 0.1860\n",
            "Epoch 651/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1868 - val_loss: 0.1861\n",
            "Epoch 652/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1868 - val_loss: 0.1860\n",
            "Epoch 653/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1860\n",
            "Epoch 654/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1859\n",
            "Epoch 655/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1859\n",
            "Epoch 656/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1859\n",
            "Epoch 657/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1859\n",
            "Epoch 658/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1860\n",
            "Epoch 659/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1859\n",
            "Epoch 660/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1867 - val_loss: 0.1859\n",
            "Epoch 661/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1866 - val_loss: 0.1859\n",
            "Epoch 662/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1866 - val_loss: 0.1857\n",
            "Epoch 663/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1865 - val_loss: 0.1858\n",
            "Epoch 664/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1865 - val_loss: 0.1859\n",
            "Epoch 665/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1866 - val_loss: 0.1857\n",
            "Epoch 666/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1865 - val_loss: 0.1858\n",
            "Epoch 667/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1865 - val_loss: 0.1857\n",
            "Epoch 668/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1865 - val_loss: 0.1857\n",
            "Epoch 669/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1865 - val_loss: 0.1856\n",
            "Epoch 670/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1864 - val_loss: 0.1856\n",
            "Epoch 671/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1864 - val_loss: 0.1857\n",
            "Epoch 672/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1864 - val_loss: 0.1856\n",
            "Epoch 673/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1864 - val_loss: 0.1856\n",
            "Epoch 674/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1864 - val_loss: 0.1856\n",
            "Epoch 675/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1863 - val_loss: 0.1855\n",
            "Epoch 676/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1863 - val_loss: 0.1855\n",
            "Epoch 677/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1862 - val_loss: 0.1855\n",
            "Epoch 678/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1862 - val_loss: 0.1855\n",
            "Epoch 679/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1862 - val_loss: 0.1855\n",
            "Epoch 680/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1862 - val_loss: 0.1855\n",
            "Epoch 681/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1861 - val_loss: 0.1853\n",
            "Epoch 682/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1862 - val_loss: 0.1854\n",
            "Epoch 683/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1862 - val_loss: 0.1854\n",
            "Epoch 684/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1861 - val_loss: 0.1853\n",
            "Epoch 685/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1861 - val_loss: 0.1853\n",
            "Epoch 686/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1860 - val_loss: 0.1853\n",
            "Epoch 687/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1860 - val_loss: 0.1852\n",
            "Epoch 688/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1860 - val_loss: 0.1853\n",
            "Epoch 689/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1860 - val_loss: 0.1853\n",
            "Epoch 690/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1860 - val_loss: 0.1852\n",
            "Epoch 691/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1859 - val_loss: 0.1852\n",
            "Epoch 692/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1859 - val_loss: 0.1852\n",
            "Epoch 693/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1859 - val_loss: 0.1852\n",
            "Epoch 694/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1859 - val_loss: 0.1850\n",
            "Epoch 695/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1858 - val_loss: 0.1852\n",
            "Epoch 696/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1858 - val_loss: 0.1851\n",
            "Epoch 697/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1858 - val_loss: 0.1851\n",
            "Epoch 698/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1858 - val_loss: 0.1850\n",
            "Epoch 699/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1858 - val_loss: 0.1850\n",
            "Epoch 700/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1857 - val_loss: 0.1849\n",
            "Epoch 701/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1857 - val_loss: 0.1849\n",
            "Epoch 702/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1857 - val_loss: 0.1849\n",
            "Epoch 703/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1856 - val_loss: 0.1849\n",
            "Epoch 704/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1856 - val_loss: 0.1848\n",
            "Epoch 705/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1856 - val_loss: 0.1848\n",
            "Epoch 706/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1856 - val_loss: 0.1848\n",
            "Epoch 707/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1856 - val_loss: 0.1849\n",
            "Epoch 708/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1855 - val_loss: 0.1848\n",
            "Epoch 709/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1855 - val_loss: 0.1847\n",
            "Epoch 710/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1854 - val_loss: 0.1847\n",
            "Epoch 711/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1855 - val_loss: 0.1847\n",
            "Epoch 712/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1854 - val_loss: 0.1847\n",
            "Epoch 713/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1854 - val_loss: 0.1846\n",
            "Epoch 714/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1854 - val_loss: 0.1846\n",
            "Epoch 715/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1853 - val_loss: 0.1846\n",
            "Epoch 716/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1853 - val_loss: 0.1845\n",
            "Epoch 717/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1853 - val_loss: 0.1845\n",
            "Epoch 718/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1853 - val_loss: 0.1845\n",
            "Epoch 719/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1852 - val_loss: 0.1845\n",
            "Epoch 720/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1852 - val_loss: 0.1844\n",
            "Epoch 721/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1852 - val_loss: 0.1844\n",
            "Epoch 722/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1852 - val_loss: 0.1844\n",
            "Epoch 723/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1852 - val_loss: 0.1844\n",
            "Epoch 724/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1851 - val_loss: 0.1844\n",
            "Epoch 725/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1852 - val_loss: 0.1843\n",
            "Epoch 726/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1851 - val_loss: 0.1843\n",
            "Epoch 727/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1851 - val_loss: 0.1843\n",
            "Epoch 728/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1851 - val_loss: 0.1842\n",
            "Epoch 729/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1850 - val_loss: 0.1842\n",
            "Epoch 730/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1850 - val_loss: 0.1843\n",
            "Epoch 731/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1850 - val_loss: 0.1842\n",
            "Epoch 732/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1850 - val_loss: 0.1842\n",
            "Epoch 733/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1849 - val_loss: 0.1842\n",
            "Epoch 734/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1850 - val_loss: 0.1841\n",
            "Epoch 735/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1849 - val_loss: 0.1841\n",
            "Epoch 736/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1849 - val_loss: 0.1841\n",
            "Epoch 737/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1848 - val_loss: 0.1841\n",
            "Epoch 738/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1848 - val_loss: 0.1840\n",
            "Epoch 739/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1848 - val_loss: 0.1840\n",
            "Epoch 740/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1848 - val_loss: 0.1840\n",
            "Epoch 741/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1848 - val_loss: 0.1840\n",
            "Epoch 742/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1847 - val_loss: 0.1839\n",
            "Epoch 743/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1847 - val_loss: 0.1839\n",
            "Epoch 744/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1847 - val_loss: 0.1839\n",
            "Epoch 745/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1847 - val_loss: 0.1839\n",
            "Epoch 746/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1846 - val_loss: 0.1838\n",
            "Epoch 747/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1846 - val_loss: 0.1838\n",
            "Epoch 748/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1846 - val_loss: 0.1838\n",
            "Epoch 749/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1846 - val_loss: 0.1838\n",
            "Epoch 750/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1846 - val_loss: 0.1839\n",
            "Epoch 751/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1845 - val_loss: 0.1837\n",
            "Epoch 752/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1845 - val_loss: 0.1837\n",
            "Epoch 753/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1845 - val_loss: 0.1837\n",
            "Epoch 754/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1844 - val_loss: 0.1837\n",
            "Epoch 755/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1845 - val_loss: 0.1837\n",
            "Epoch 756/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1844 - val_loss: 0.1836\n",
            "Epoch 757/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1844 - val_loss: 0.1837\n",
            "Epoch 758/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1844 - val_loss: 0.1836\n",
            "Epoch 759/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1844 - val_loss: 0.1836\n",
            "Epoch 760/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1844 - val_loss: 0.1836\n",
            "Epoch 761/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1843 - val_loss: 0.1835\n",
            "Epoch 762/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1843 - val_loss: 0.1835\n",
            "Epoch 763/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1843 - val_loss: 0.1835\n",
            "Epoch 764/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1843 - val_loss: 0.1835\n",
            "Epoch 765/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1842 - val_loss: 0.1834\n",
            "Epoch 766/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1842 - val_loss: 0.1834\n",
            "Epoch 767/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1842 - val_loss: 0.1834\n",
            "Epoch 768/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1841 - val_loss: 0.1833\n",
            "Epoch 769/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1841 - val_loss: 0.1834\n",
            "Epoch 770/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1841 - val_loss: 0.1834\n",
            "Epoch 771/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1841 - val_loss: 0.1834\n",
            "Epoch 772/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1841 - val_loss: 0.1833\n",
            "Epoch 773/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1841 - val_loss: 0.1833\n",
            "Epoch 774/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1840 - val_loss: 0.1833\n",
            "Epoch 775/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1840 - val_loss: 0.1833\n",
            "Epoch 776/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1840 - val_loss: 0.1832\n",
            "Epoch 777/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1840 - val_loss: 0.1832\n",
            "Epoch 778/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1840 - val_loss: 0.1832\n",
            "Epoch 779/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1839 - val_loss: 0.1832\n",
            "Epoch 780/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1839 - val_loss: 0.1831\n",
            "Epoch 781/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1839 - val_loss: 0.1832\n",
            "Epoch 782/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1840 - val_loss: 0.1832\n",
            "Epoch 783/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1839 - val_loss: 0.1831\n",
            "Epoch 784/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1839 - val_loss: 0.1831\n",
            "Epoch 785/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1839 - val_loss: 0.1831\n",
            "Epoch 786/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1838 - val_loss: 0.1830\n",
            "Epoch 787/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1838 - val_loss: 0.1830\n",
            "Epoch 788/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1837 - val_loss: 0.1829\n",
            "Epoch 789/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1837 - val_loss: 0.1830\n",
            "Epoch 790/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1838 - val_loss: 0.1830\n",
            "Epoch 791/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1837 - val_loss: 0.1830\n",
            "Epoch 792/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1837 - val_loss: 0.1829\n",
            "Epoch 793/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1836 - val_loss: 0.1829\n",
            "Epoch 794/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1836 - val_loss: 0.1829\n",
            "Epoch 795/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1836 - val_loss: 0.1828\n",
            "Epoch 796/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1836 - val_loss: 0.1829\n",
            "Epoch 797/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1836 - val_loss: 0.1828\n",
            "Epoch 798/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1835 - val_loss: 0.1828\n",
            "Epoch 799/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1836 - val_loss: 0.1828\n",
            "Epoch 800/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1835 - val_loss: 0.1827\n",
            "Epoch 801/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1835 - val_loss: 0.1827\n",
            "Epoch 802/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1835 - val_loss: 0.1827\n",
            "Epoch 803/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1835 - val_loss: 0.1827\n",
            "Epoch 804/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1835 - val_loss: 0.1827\n",
            "Epoch 805/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1834 - val_loss: 0.1828\n",
            "Epoch 806/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1834 - val_loss: 0.1827\n",
            "Epoch 807/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1835 - val_loss: 0.1827\n",
            "Epoch 808/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1834 - val_loss: 0.1827\n",
            "Epoch 809/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1834 - val_loss: 0.1826\n",
            "Epoch 810/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1834 - val_loss: 0.1826\n",
            "Epoch 811/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1833 - val_loss: 0.1826\n",
            "Epoch 812/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1833 - val_loss: 0.1826\n",
            "Epoch 813/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1834 - val_loss: 0.1827\n",
            "Epoch 814/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1833 - val_loss: 0.1826\n",
            "Epoch 815/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1833 - val_loss: 0.1826\n",
            "Epoch 816/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1833 - val_loss: 0.1825\n",
            "Epoch 817/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1832 - val_loss: 0.1825\n",
            "Epoch 818/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1832 - val_loss: 0.1825\n",
            "Epoch 819/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1832 - val_loss: 0.1825\n",
            "Epoch 820/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1832 - val_loss: 0.1825\n",
            "Epoch 821/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1832 - val_loss: 0.1824\n",
            "Epoch 822/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1831 - val_loss: 0.1824\n",
            "Epoch 823/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1831 - val_loss: 0.1823\n",
            "Epoch 824/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1831 - val_loss: 0.1823\n",
            "Epoch 825/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1831 - val_loss: 0.1825\n",
            "Epoch 826/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1831 - val_loss: 0.1823\n",
            "Epoch 827/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1830 - val_loss: 0.1823\n",
            "Epoch 828/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1830 - val_loss: 0.1823\n",
            "Epoch 829/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1830 - val_loss: 0.1823\n",
            "Epoch 830/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1830 - val_loss: 0.1823\n",
            "Epoch 831/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1830 - val_loss: 0.1824\n",
            "Epoch 832/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1830 - val_loss: 0.1823\n",
            "Epoch 833/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1830 - val_loss: 0.1822\n",
            "Epoch 834/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1829 - val_loss: 0.1822\n",
            "Epoch 835/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1829 - val_loss: 0.1822\n",
            "Epoch 836/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1829 - val_loss: 0.1821\n",
            "Epoch 837/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1829 - val_loss: 0.1821\n",
            "Epoch 838/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1829 - val_loss: 0.1822\n",
            "Epoch 839/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1829 - val_loss: 0.1822\n",
            "Epoch 840/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1828 - val_loss: 0.1821\n",
            "Epoch 841/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1828 - val_loss: 0.1820\n",
            "Epoch 842/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1828 - val_loss: 0.1820\n",
            "Epoch 843/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1828 - val_loss: 0.1821\n",
            "Epoch 844/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1828 - val_loss: 0.1820\n",
            "Epoch 845/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1827 - val_loss: 0.1820\n",
            "Epoch 846/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1827 - val_loss: 0.1820\n",
            "Epoch 847/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1827 - val_loss: 0.1819\n",
            "Epoch 848/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1826 - val_loss: 0.1819\n",
            "Epoch 849/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1827 - val_loss: 0.1819\n",
            "Epoch 850/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1826 - val_loss: 0.1819\n",
            "Epoch 851/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1826 - val_loss: 0.1818\n",
            "Epoch 852/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1826 - val_loss: 0.1819\n",
            "Epoch 853/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1826 - val_loss: 0.1819\n",
            "Epoch 854/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1826 - val_loss: 0.1819\n",
            "Epoch 855/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1826 - val_loss: 0.1818\n",
            "Epoch 856/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1825 - val_loss: 0.1817\n",
            "Epoch 857/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1825 - val_loss: 0.1817\n",
            "Epoch 858/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1824 - val_loss: 0.1817\n",
            "Epoch 859/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1824 - val_loss: 0.1817\n",
            "Epoch 860/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1824 - val_loss: 0.1817\n",
            "Epoch 861/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1824 - val_loss: 0.1817\n",
            "Epoch 862/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1824 - val_loss: 0.1817\n",
            "Epoch 863/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1824 - val_loss: 0.1816\n",
            "Epoch 864/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1823 - val_loss: 0.1816\n",
            "Epoch 865/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1823 - val_loss: 0.1816\n",
            "Epoch 866/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1823 - val_loss: 0.1816\n",
            "Epoch 867/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1823 - val_loss: 0.1816\n",
            "Epoch 868/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1823 - val_loss: 0.1816\n",
            "Epoch 869/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1822 - val_loss: 0.1815\n",
            "Epoch 870/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1822 - val_loss: 0.1815\n",
            "Epoch 871/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1822 - val_loss: 0.1815\n",
            "Epoch 872/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1822 - val_loss: 0.1815\n",
            "Epoch 873/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1822 - val_loss: 0.1815\n",
            "Epoch 874/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1821 - val_loss: 0.1814\n",
            "Epoch 875/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1821 - val_loss: 0.1814\n",
            "Epoch 876/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1821 - val_loss: 0.1814\n",
            "Epoch 877/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1821 - val_loss: 0.1814\n",
            "Epoch 878/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1821 - val_loss: 0.1814\n",
            "Epoch 879/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1821 - val_loss: 0.1814\n",
            "Epoch 880/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1820 - val_loss: 0.1813\n",
            "Epoch 881/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1820 - val_loss: 0.1813\n",
            "Epoch 882/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1820 - val_loss: 0.1813\n",
            "Epoch 883/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1820 - val_loss: 0.1813\n",
            "Epoch 884/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1820 - val_loss: 0.1812\n",
            "Epoch 885/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1820 - val_loss: 0.1813\n",
            "Epoch 886/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1819 - val_loss: 0.1812\n",
            "Epoch 887/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1819 - val_loss: 0.1812\n",
            "Epoch 888/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1819 - val_loss: 0.1812\n",
            "Epoch 889/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1819 - val_loss: 0.1812\n",
            "Epoch 890/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1819 - val_loss: 0.1811\n",
            "Epoch 891/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1818 - val_loss: 0.1811\n",
            "Epoch 892/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1819 - val_loss: 0.1811\n",
            "Epoch 893/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1819 - val_loss: 0.1812\n",
            "Epoch 894/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1818 - val_loss: 0.1811\n",
            "Epoch 895/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1818 - val_loss: 0.1811\n",
            "Epoch 896/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1817 - val_loss: 0.1810\n",
            "Epoch 897/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1817 - val_loss: 0.1810\n",
            "Epoch 898/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1817 - val_loss: 0.1810\n",
            "Epoch 899/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1817 - val_loss: 0.1810\n",
            "Epoch 900/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1817 - val_loss: 0.1810\n",
            "Epoch 901/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1817 - val_loss: 0.1809\n",
            "Epoch 902/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1816 - val_loss: 0.1809\n",
            "Epoch 903/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1816 - val_loss: 0.1809\n",
            "Epoch 904/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1816 - val_loss: 0.1809\n",
            "Epoch 905/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1816 - val_loss: 0.1809\n",
            "Epoch 906/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1816 - val_loss: 0.1810\n",
            "Epoch 907/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1815 - val_loss: 0.1808\n",
            "Epoch 908/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1815 - val_loss: 0.1808\n",
            "Epoch 909/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1815 - val_loss: 0.1808\n",
            "Epoch 910/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1815 - val_loss: 0.1807\n",
            "Epoch 911/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1814 - val_loss: 0.1807\n",
            "Epoch 912/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1815 - val_loss: 0.1807\n",
            "Epoch 913/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1815 - val_loss: 0.1807\n",
            "Epoch 914/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1815 - val_loss: 0.1807\n",
            "Epoch 915/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1815 - val_loss: 0.1807\n",
            "Epoch 916/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1814 - val_loss: 0.1807\n",
            "Epoch 917/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1814 - val_loss: 0.1807\n",
            "Epoch 918/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1814 - val_loss: 0.1806\n",
            "Epoch 919/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1813 - val_loss: 0.1806\n",
            "Epoch 920/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1814 - val_loss: 0.1807\n",
            "Epoch 921/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1814 - val_loss: 0.1806\n",
            "Epoch 922/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1813 - val_loss: 0.1805\n",
            "Epoch 923/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1813 - val_loss: 0.1805\n",
            "Epoch 924/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1813 - val_loss: 0.1805\n",
            "Epoch 925/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1812 - val_loss: 0.1805\n",
            "Epoch 926/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1812 - val_loss: 0.1805\n",
            "Epoch 927/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1812 - val_loss: 0.1805\n",
            "Epoch 928/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1812 - val_loss: 0.1805\n",
            "Epoch 929/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1812 - val_loss: 0.1804\n",
            "Epoch 930/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1811 - val_loss: 0.1804\n",
            "Epoch 931/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1811 - val_loss: 0.1804\n",
            "Epoch 932/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1811 - val_loss: 0.1804\n",
            "Epoch 933/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1811 - val_loss: 0.1804\n",
            "Epoch 934/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1811 - val_loss: 0.1805\n",
            "Epoch 935/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1811 - val_loss: 0.1803\n",
            "Epoch 936/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1803\n",
            "Epoch 937/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1803\n",
            "Epoch 938/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1803\n",
            "Epoch 939/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1802\n",
            "Epoch 940/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1803\n",
            "Epoch 941/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1802\n",
            "Epoch 942/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1803\n",
            "Epoch 943/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1810 - val_loss: 0.1802\n",
            "Epoch 944/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1809 - val_loss: 0.1802\n",
            "Epoch 945/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1809 - val_loss: 0.1802\n",
            "Epoch 946/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1809 - val_loss: 0.1802\n",
            "Epoch 947/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1801\n",
            "Epoch 948/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1809 - val_loss: 0.1801\n",
            "Epoch 949/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1801\n",
            "Epoch 950/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1801\n",
            "Epoch 951/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1800\n",
            "Epoch 952/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1800\n",
            "Epoch 953/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1801\n",
            "Epoch 954/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1800\n",
            "Epoch 955/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1800\n",
            "Epoch 956/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1800\n",
            "Epoch 957/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1800\n",
            "Epoch 958/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1808 - val_loss: 0.1801\n",
            "Epoch 959/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1807 - val_loss: 0.1800\n",
            "Epoch 960/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1807 - val_loss: 0.1799\n",
            "Epoch 961/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1807 - val_loss: 0.1799\n",
            "Epoch 962/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1806 - val_loss: 0.1799\n",
            "Epoch 963/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1807 - val_loss: 0.1799\n",
            "Epoch 964/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1806 - val_loss: 0.1799\n",
            "Epoch 965/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1806 - val_loss: 0.1799\n",
            "Epoch 966/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1806 - val_loss: 0.1799\n",
            "Epoch 967/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1806 - val_loss: 0.1798\n",
            "Epoch 968/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1805 - val_loss: 0.1798\n",
            "Epoch 969/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1805 - val_loss: 0.1797\n",
            "Epoch 970/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1805 - val_loss: 0.1798\n",
            "Epoch 971/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1804 - val_loss: 0.1798\n",
            "Epoch 972/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1805 - val_loss: 0.1797\n",
            "Epoch 973/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1805 - val_loss: 0.1798\n",
            "Epoch 974/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1805 - val_loss: 0.1798\n",
            "Epoch 975/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1804 - val_loss: 0.1797\n",
            "Epoch 976/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1804 - val_loss: 0.1797\n",
            "Epoch 977/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1804 - val_loss: 0.1797\n",
            "Epoch 978/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1804 - val_loss: 0.1796\n",
            "Epoch 979/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1803 - val_loss: 0.1796\n",
            "Epoch 980/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1803 - val_loss: 0.1796\n",
            "Epoch 981/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1803 - val_loss: 0.1796\n",
            "Epoch 982/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1803 - val_loss: 0.1796\n",
            "Epoch 983/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1803 - val_loss: 0.1796\n",
            "Epoch 984/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1803 - val_loss: 0.1795\n",
            "Epoch 985/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1803 - val_loss: 0.1796\n",
            "Epoch 986/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1803 - val_loss: 0.1795\n",
            "Epoch 987/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1802 - val_loss: 0.1795\n",
            "Epoch 988/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1802 - val_loss: 0.1795\n",
            "Epoch 989/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1802 - val_loss: 0.1795\n",
            "Epoch 990/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1802 - val_loss: 0.1794\n",
            "Epoch 991/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1801 - val_loss: 0.1794\n",
            "Epoch 992/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1801 - val_loss: 0.1794\n",
            "Epoch 993/1000\n",
            "469/469 [==============================] - 6s 13ms/step - loss: 0.1801 - val_loss: 0.1794\n",
            "Epoch 994/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1801 - val_loss: 0.1794\n",
            "Epoch 995/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1801 - val_loss: 0.1794\n",
            "Epoch 996/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1801 - val_loss: 0.1794\n",
            "Epoch 997/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1801 - val_loss: 0.1793\n",
            "Epoch 998/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1800 - val_loss: 0.1793\n",
            "Epoch 999/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1800 - val_loss: 0.1793\n",
            "Epoch 1000/1000\n",
            "469/469 [==============================] - 6s 12ms/step - loss: 0.1800 - val_loss: 0.1793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKTfcR4oaOVj"
      },
      "source": [
        "#saving model\n",
        "autoencoder.save('autoenc_1000_epoch.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9-mP9IZFgLd"
      },
      "source": [
        "#Making Predictions\n",
        "# to predict the reconstructed images for the original images...\n",
        "pred = autoencoder.predict(test_X_noisy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "F8aaL_SOF2Aw",
        "outputId": "cc44aa38-27d4-4370-e802-dc0606043c28"
      },
      "source": [
        "#Visualizing original image\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
        "    plt.yticks([]) # to remove y-axis\n",
        "    plt.grid(False) # to remove grid\n",
        "    plt.imshow(test_X[i].reshape(28, 28), cmap='gray') #display the image \n",
        "plt.tight_layout() # to have a proper space in the subplots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "dYe4hlXBF4mm",
        "outputId": "a5750518-0346-4578-9ae6-3fc9c746c867"
      },
      "source": [
        "#visualizing noise image\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
        "    plt.yticks([]) # to remove y-axis\n",
        "    plt.grid(False) # to remove grid\n",
        "    plt.imshow(test_X_noisy[i].reshape(28, 28), cmap='gray') #display the image \n",
        "plt.tight_layout() # to have a proper space in the subplots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "NtUHoN0rF7Rl",
        "outputId": "3200e977-ece8-4b2c-9b56-175950711bdf"
      },
      "source": [
        "# to visualize reconstructed images(output of autoencoder)\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i+1)\n",
        "    plt.xticks([]) # to remove x-axis  the [] empty list indicates this\n",
        "    plt.yticks([]) # to remove y-axis\n",
        "    plt.grid(False) # to remove grid\n",
        "    plt.imshow(pred[i].reshape(28, 28), cmap='gray') #display the image \n",
        "plt.tight_layout() # to have a proper space in the subplots\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}